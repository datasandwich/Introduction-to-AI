{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score,cross_validate, train_test_split\n",
    "from sklearn.dummy import DummyRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Don't forget to change the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/datasandwich/Documents/AI\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/datasandwich/Documents/AI\n",
    "data = pd.read_csv('coursework1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.00000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.764381</td>\n",
       "      <td>1013.19924</td>\n",
       "      <td>79.124174</td>\n",
       "      <td>4.200294</td>\n",
       "      <td>25.419061</td>\n",
       "      <td>1083.798770</td>\n",
       "      <td>545.396183</td>\n",
       "      <td>134.188464</td>\n",
       "      <td>12.102353</td>\n",
       "      <td>68.190934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.574323</td>\n",
       "      <td>6.41076</td>\n",
       "      <td>13.793439</td>\n",
       "      <td>0.760197</td>\n",
       "      <td>4.173916</td>\n",
       "      <td>16.527806</td>\n",
       "      <td>7.866803</td>\n",
       "      <td>15.829717</td>\n",
       "      <td>1.103196</td>\n",
       "      <td>10.470586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.522300</td>\n",
       "      <td>985.85000</td>\n",
       "      <td>30.344000</td>\n",
       "      <td>2.087400</td>\n",
       "      <td>17.878000</td>\n",
       "      <td>1000.800000</td>\n",
       "      <td>512.450000</td>\n",
       "      <td>100.170000</td>\n",
       "      <td>9.904400</td>\n",
       "      <td>27.765000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.408000</td>\n",
       "      <td>1008.90000</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>3.723900</td>\n",
       "      <td>23.294000</td>\n",
       "      <td>1079.600000</td>\n",
       "      <td>542.170000</td>\n",
       "      <td>127.985000</td>\n",
       "      <td>11.622000</td>\n",
       "      <td>61.303500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.186000</td>\n",
       "      <td>1012.80000</td>\n",
       "      <td>82.266000</td>\n",
       "      <td>4.186200</td>\n",
       "      <td>25.082000</td>\n",
       "      <td>1088.700000</td>\n",
       "      <td>549.890000</td>\n",
       "      <td>133.780000</td>\n",
       "      <td>12.025000</td>\n",
       "      <td>66.601000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.862500</td>\n",
       "      <td>1016.90000</td>\n",
       "      <td>90.043500</td>\n",
       "      <td>4.550900</td>\n",
       "      <td>27.184000</td>\n",
       "      <td>1096.000000</td>\n",
       "      <td>550.060000</td>\n",
       "      <td>140.895000</td>\n",
       "      <td>12.578000</td>\n",
       "      <td>73.935500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34.929000</td>\n",
       "      <td>1034.20000</td>\n",
       "      <td>100.200000</td>\n",
       "      <td>7.610600</td>\n",
       "      <td>37.402000</td>\n",
       "      <td>1100.800000</td>\n",
       "      <td>550.610000</td>\n",
       "      <td>174.610000</td>\n",
       "      <td>15.081000</td>\n",
       "      <td>119.890000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AT           AP            AH          AFDP          GTEP  \\\n",
       "count  15039.000000  15039.00000  15039.000000  15039.000000  15039.000000   \n",
       "mean      17.764381   1013.19924     79.124174      4.200294     25.419061   \n",
       "std        7.574323      6.41076     13.793439      0.760197      4.173916   \n",
       "min        0.522300    985.85000     30.344000      2.087400     17.878000   \n",
       "25%       11.408000   1008.90000     69.750000      3.723900     23.294000   \n",
       "50%       18.186000   1012.80000     82.266000      4.186200     25.082000   \n",
       "75%       23.862500   1016.90000     90.043500      4.550900     27.184000   \n",
       "max       34.929000   1034.20000    100.200000      7.610600     37.402000   \n",
       "\n",
       "                TIT           TAT           TEY           CDP           NOX  \n",
       "count  15039.000000  15039.000000  15039.000000  15039.000000  15039.000000  \n",
       "mean    1083.798770    545.396183    134.188464     12.102353     68.190934  \n",
       "std       16.527806      7.866803     15.829717      1.103196     10.470586  \n",
       "min     1000.800000    512.450000    100.170000      9.904400     27.765000  \n",
       "25%     1079.600000    542.170000    127.985000     11.622000     61.303500  \n",
       "50%     1088.700000    549.890000    133.780000     12.025000     66.601000  \n",
       "75%     1096.000000    550.060000    140.895000     12.578000     73.935500  \n",
       "max     1100.800000    550.610000    174.610000     15.081000    119.890000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data['NOX'],kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline coefficient of determination: -7.300965809187154e-05\n"
     ]
    }
   ],
   "source": [
    "X = data.drop('NOX',axis=1)\n",
    "y = data['NOX']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "clf = DummyRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "base_line = clf.score(X_test, y_test)\n",
    "print(\"Baseline coefficient of determination: {}\".format(base_line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosting regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most successful iteration: 8th, Optimal number of estimators: 10, Optimal tree depth: 13, Optimal learning rate: 1, Fit time: 0.7769324779510498\n",
      "Refitting with optimal parameters!\n",
      "Negative mean squared error (5-fold average): -50.484149315188674\n",
      "Training coefficient of determination (5-fold average): 0.9962596004708548\n",
      "Testing coefficient of determination (5-fold average): 0.2586750861269104\n",
      "COMPLETE\n"
     ]
    }
   ],
   "source": [
    "X = data.drop('NOX',axis=1)\n",
    "y = data['NOX']\n",
    "parameters = {'learning_rate':[0.1,1], 'n_estimators':[1, 10],'max_depth':[3,13]}\n",
    "reg = ensemble.GradientBoostingRegressor(**parameters)\n",
    "clf_gb = GridSearchCV(reg, parameters,cv=5)\n",
    "clf_gb.fit(X, y)\n",
    "\n",
    "index=clf_gb.cv_results_['rank_test_score'][0]\n",
    "n_estimators=clf_gb.cv_results_['param_n_estimators'][index-1]\n",
    "max_depth=clf_gb.cv_results_['param_max_depth'][index-1]\n",
    "learning_rate=clf_gb.cv_results_['param_learning_rate'][index-1]\n",
    "fit_time_gb=clf_gb.cv_results_['mean_fit_time'][index-1]\n",
    "print(\n",
    "    \"Most successful iteration: {}th, Optimal number of estimators: {}, Optimal tree depth: {}, Optimal learning rate: {}, Fit time: {}\".format(\n",
    "        index,\n",
    "        n_estimators,\n",
    "        max_depth,\n",
    "        learning_rate,\n",
    "        fit_time_gb)\n",
    "    )\n",
    "\n",
    "print(\"Refitting with optimal parameters!\")\n",
    "\n",
    "parameters = {'learning_rate':learning_rate, 'n_estimators':n_estimators,'max_depth':max_depth}\n",
    "reg = ensemble.GradientBoostingRegressor(**parameters)\n",
    "scores = cross_validate(reg, X, y, cv=5,\n",
    "                        scoring=('r2', 'neg_mean_squared_error'),\n",
    "                        return_train_score=True)\n",
    "\n",
    "print(\"Negative mean squared error (5-fold average): {}\".format(scores['test_neg_mean_squared_error'].mean()))\n",
    "\n",
    "print(\"Training coefficient of determination (5-fold average): {}\".format(scores['train_r2'].mean()))\n",
    "\n",
    "scores = cross_validate(reg, X, y, cv=5,\n",
    "                        scoring=('r2'),\n",
    "                        return_train_score=False)\n",
    "\n",
    "r2_GB=scores['test_score'].mean()\n",
    "\n",
    "print(\"Testing coefficient of determination (5-fold average): {}\".format(r2_GB))\n",
    "\n",
    "print(\"COMPLETE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most successful iteration: 4th, Optimal C: 10, Optimal epsilon: 1, Fit time: 2.683878707885742\n",
      "Refitting with optimal parameters!\n",
      "Negative mean squared error (3-fold average): -107.97068864338839\n",
      "Training coefficient of determination (3-fold average): 0.2828652597114963\n",
      "Testing coefficient of determination (3-fold average): -0.05363543626938031\n",
      "COMPLETE\n"
     ]
    }
   ],
   "source": [
    "X = data.drop('NOX',axis=1)\n",
    "y = data['NOX']\n",
    "scaler=StandardScaler() \n",
    "scaler.fit_transform(X,y)\n",
    "parameters = { 'C':[1, 10],'epsilon':[0.1,1]}\n",
    "regr = SVR()\n",
    "clf_svr = GridSearchCV(regr, parameters,cv=5)\n",
    "clf_svr.fit(X, y)\n",
    "\n",
    "index=clf_svr.cv_results_['rank_test_score'][0]\n",
    "C=clf_svr.cv_results_['param_C'][index-1]\n",
    "epsilon=clf_svr.cv_results_['param_epsilon'][index-1]\n",
    "fit_time_svr=clf_svr.cv_results_['mean_fit_time'][index-1]\n",
    "\n",
    "print(\n",
    "    \"Most successful iteration: {}th, Optimal C: {}, Optimal epsilon: {}, Fit time: {}\".format(\n",
    "    index,\n",
    "    C,\n",
    "    epsilon,\n",
    "    fit_time_svr)\n",
    "    )\n",
    "\n",
    "print(\"Refitting with optimal parameters!\")\n",
    "\n",
    "parameters = { 'C':C,'epsilon':epsilon}\n",
    "regr = SVR(**parameters)\n",
    "scores = cross_validate(regr, X, y, cv=3,\n",
    "                        scoring=('r2', 'neg_mean_squared_error'),\n",
    "                        return_train_score=True)\n",
    "print(\"Negative mean squared error (3-fold average): {}\".format(scores['test_neg_mean_squared_error'].mean()))\n",
    "\n",
    "print(\"Training coefficient of determination (3-fold average): {}\".format(scores['train_r2'].mean()))\n",
    "\n",
    "scores = cross_validate(regr, X, y, cv=3,\n",
    "                        scoring=('r2'),\n",
    "                        return_train_score=False)\n",
    "\n",
    "r2_SVR=scores['test_score'].mean()\n",
    "\n",
    "print(\"Testing coefficient of determination (3-fold average): {}\".format(r2_SVR))\n",
    "\n",
    "print(\"COMPLETE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient boosting is 3.4544555467210603 times faster than SVR\n"
     ]
    }
   ],
   "source": [
    "fit_time_ratio=fit_time_svr/fit_time_gb\n",
    "print(\"Gradient boosting is {} times faster than SVR\".format(fit_time_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save time, it is possible to use a linear kernel instead of an rbf kernel for the SVR. However, with the SVR model currently boasting a testing r^2 score of -0.05, this avenue is not worth exploring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test set score overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB: 0.2586750861269104 SVR: -0.05363543626938031 Base line: -7.300965809187154e-05\n"
     ]
    }
   ],
   "source": [
    "print(\"GB: {}\".format(r2_GB),\n",
    "      \"SVR: {}\".format(r2_SVR),\n",
    "      \"Base line: {}\".format(base_line)\n",
    "     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
